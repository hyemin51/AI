import sys, os
import random
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

# LangChain / OpenAI ê´€ë ¨
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# ----------------------------------------------------------------
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Streamlit Secrets ë˜ëŠ” .env)
# ----------------------------------------------------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ----------------------------------------------------------------
# RAG ìœ í‹¸ í•¨ìˆ˜ë“¤ (ì›ë˜ rag_pipeline.py ì•ˆì— ìˆë˜ ë‚´ìš©)
# ----------------------------------------------------------------

def load_docs(docs_path="docs"):
    """
    docs í´ë” ì•ˆì˜ pdf / txt íŒŒì¼ì„ ëª¨ë‘ ì½ì–´ì„œ LangChain ë¬¸ì„œë“¤(list[Document])ë¡œ ë°˜í™˜
    """
    docs = []

    # PDF ë¡œë”
    pdf_loader = DirectoryLoader(
        docs_path,
        glob="*.pdf",
        loader_cls=PyPDFLoader,
    )
    docs.extend(pdf_loader.load())

    # TXT ë¡œë”
    txt_loader = DirectoryLoader(
        docs_path,
        glob="*.txt",
        loader_cls=TextLoader,
    )
    docs.extend(txt_loader.load())

    return docs


def split_docs(documents, chunk_size=800, chunk_overlap=150):
    """
    ê¸´ ë¬¸ì„œë¥¼ LLMì´ ë‹¤ë£° ìˆ˜ ìˆê²Œ ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    return splitter.split_documents(documents)


def build_vectorstore(chunks, save_path="vectorstore"):
    """
    ë¶„í• ëœ ë¬¸ì„œ(chunks)ë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ë²¡í„°í™”í•˜ê³ ,
    FAISS ë²¡í„°ìŠ¤í† ì–´ë¡œ ë§Œë“¤ê³  ë””ìŠ¤í¬ì— ì €ì¥
    """
    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
    vectordb = FAISS.from_documents(chunks, embedding=embeddings)
    vectordb.save_local(save_path)
    return vectordb


def load_vectorstore(save_path="vectorstore"):
    """
    ì´ë¯¸ ë§Œë“¤ì–´ë‘” FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë””ìŠ¤í¬ì—ì„œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
    """
    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
    vectordb = FAISS.load_local(
        save_path,
        embeddings,
        allow_dangerous_deserialization=True,  # FAISSì—ì„œ í•„ìš”
    )
    return vectordb


def make_answer_function(vectordb):
    """
    ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë°›ì•„ì„œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ q -> ë‹µë³€ í…ìŠ¤íŠ¸ ë¥¼ ëŒë ¤ì£¼ëŠ” answer_fn ì„ ë§Œë“¤ì–´ ëŒë ¤ì¤Œ
    (RetrievalQA ë¹„ìŠ·í•˜ê²Œ ì§ì ‘ êµ¬ì„±)
    """

    retriever = vectordb.as_retriever(search_kwargs={"k": 3})

    prompt = ChatPromptTemplate.from_template(
        """ë„ˆëŠ” íšŒê³„ ê³¼ëª© ë³´ì¡° ê°•ì‚¬ì•¼.
ì•„ë˜ëŠ” ì°¸ê³ í•  ë¬¸ì„œ ë‚´ìš©ì´ì•¼:

{context}

ì‚¬ìš©ì ì§ˆë¬¸:
{question}

ë¬¸ì„œì—ì„œ ê·¼ê±°ë¥¼ ì‚¬ìš©í•´ì„œ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.
ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´. ê·¼ê±° ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ˆ."""
    )

    def answer_fn(user_question: str) -> str:
        # 1) ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        docs = retriever.get_relevant_documents(user_question)
        context_text = "\n\n".join([d.page_content for d in docs])

        # 2) LLM í˜¸ì¶œ ì¤€ë¹„
        llm = ChatOpenAI(
            api_key=OPENAI_API_KEY,
            model="gpt-4o-mini",
            temperature=0.2,
        )

        # 3) í”„ë¡¬í”„íŠ¸ ì±„ìš°ê¸°
        filled_prompt = prompt.format(
            context=context_text,
            question=user_question,
        )

        # 4) ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œ
        response = llm.invoke(filled_prompt)

        # responseëŠ” ë©”ì‹œì§€ ê°ì²´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ content ì†ì„±ì„ ìš°ì„  ì‚¬ìš©
        return getattr(response, "content", str(response))

    return answer_fn


# ----------------------------------------------------------------
# Streamlit UI ì‹œì‘
# ----------------------------------------------------------------

st.set_page_config(
    page_title="ë‚˜ë§Œì˜ íšŒê³„ íŠœí„°",
    page_icon="ğŸ“š",
    layout="wide"
)

st.title("ğŸ“š ë‚˜ë§Œì˜ íšŒê³„ RAG + í€´ì¦ˆ ì±—ë´‡")
st.write(
    "ì´ ì•±ì€ GitHub ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ëœ ìë£Œë§Œìœ¼ë¡œ ë™ì‘í•´ìš”. "
    "ë¡œì»¬ PC ê²½ë¡œì— ì˜ì¡´í•˜ì§€ ì•Šì•„ìš” ğŸ‘"
)
st.write(
    "â€¢ ë¬¸ì œ ì€í–‰: `data/accounting_bank_full.csv`\n"
    "â€¢ ë‚œì´ë„ë³„ ëœë¤ ì¶œì œ ê°€ëŠ¥ (easy / medium / hard / ì „ì²´)\n"
    "â€¢ ì•„ë˜ ì…ë ¥ì°½ì— íšŒê³„ ì§ˆë¬¸ì„ ì ìœ¼ë©´ ì‹¤ì œ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•´ì¤˜ìš” âœ¨"
)

st.markdown("---")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state["history"] = []

if "answer_fn" not in st.session_state:
    st.session_state["answer_fn"] = None

if "vector_ready" not in st.session_state:
    st.session_state["vector_ready"] = False

# --------------------------------------------------
# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ or ìƒˆë¡œ êµ¬ì¶•
# --------------------------------------------------
if not st.session_state["vector_ready"]:
    try:
        vectordb = load_vectorstore("vectorstore")
    except Exception:
        try:
            docs = load_docs("docs")      # docs/ ì•ˆ PDF, TXT
            chunks = split_docs(docs)     # ì²­í¬ ë‚˜ëˆ„ê¸°
            vectordb = build_vectorstore(
                chunks,
                save_path="vectorstore"
            )
        except Exception as e:
            vectordb = None
            st.error(
                "âŒ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”. "
                "docs í´ë”ì™€ OPENAI_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
            st.code(str(e), language="text")

    if vectordb is not None:
        st.session_state["answer_fn"] = make_answer_function(vectordb)
        st.session_state["vector_ready"] = True

# --------------------------------------------------
# íšŒê³„ ì§ˆë¬¸ ì˜ì—­
# --------------------------------------------------
st.markdown("## ğŸ’¬ íšŒê³„ ì§ˆë¬¸í•´ ë³´ì„¸ìš”")

user_q = st.text_input(
    "ì˜ˆ: 'ìì‚°ì´ ë­ì˜ˆìš”?', 'ë°œìƒì£¼ì˜ íšŒê³„ë¥¼ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜', 'ì„ ê¸‰ë¹„ìš©ì€ ì™œ ìì‚°ì´ì—ìš”?' ë“±",
    key="question_input_cloudonly",
)

ask_button = st.button("ì§ˆë¬¸í•˜ê¸°")

if ask_button:
    if not user_q.strip():
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif not st.session_state["vector_ready"]:
        st.error("RAG ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì–´ìš” (ë²¡í„°ìŠ¤í† ì–´ ì¤€ë¹„ ì‹¤íŒ¨).")
    else:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            answer_text = st.session_state["answer_fn"](user_q)

        st.session_state["history"].append({"role": "user", "content": user_q})
        st.session_state["history"].append({"role": "assistant", "content": answer_text})

        st.markdown("#### ğŸ“Œ ë‹µë³€")
        st.write(answer_text)

st.markdown("---")

# --------------------------------------------------
# íšŒê³„ í€´ì¦ˆ ì„¹ì…˜
# --------------------------------------------------
st.markdown("## ğŸ“ íšŒê³„ì›ë¦¬ í€´ì¦ˆ")

CSV_PATH = "data/accounting_bank_full.csv"

@st.cache_data
def load_question_bank(csv_path: str):
    df = pd.read_csv(csv_path)

    needed_cols = [
        "week",
        "topic",
        "question",
        "choices",
        "answer",
        "explanation",
        "difficulty",
    ]
    return df[needed_cols]

bank_df = None
load_error = None
try:
    bank_df = load_question_bank(CSV_PATH)
except Exception as e:
    load_error = str(e)

left_col, right_col = st.columns(2)

with left_col:
    st.markdown("#### ğŸ” ëœë¤ ë¬¸ì œ ë°›ê¸°")
    quiz_btn = st.button("ë¬¸ì œ ì¶œì œ")

with right_col:
    difficulty_choice = st.selectbox(
        "ë‚œì´ë„ ì„ íƒ:",
        ["ì „ì²´", "easy", "medium", "hard"],
        index=0,
    )

if bank_df is None:
    st.error("âŒ í€´ì¦ˆ CSVë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆì–´ìš”. (data/accounting_bank_full.csv)")
    if load_error:
        st.code(load_error, language="text")
else:
    if quiz_btn:
        # ë‚œì´ë„ë³„ ë¬¸ì œ í’€ì—ì„œ í•˜ë‚˜ ë½‘ê¸°
        if difficulty_choice == "ì „ì²´":
            pool_df = bank_df
        else:
            pool_df = bank_df[bank_df["difficulty"] == difficulty_choice]

        if len(pool_df) == 0:
            st.warning(f"'{difficulty_choice}' ë‚œì´ë„ ë¬¸ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.")
        else:
            row = pool_df.sample(1).iloc[0]

            st.markdown(f"**ğŸ“š ì£¼ì°¨:** {row['week']}ì£¼ì°¨ / **ì£¼ì œ:** {row['topic']}")
            st.markdown("**â“ ë¬¸ì œ**")
            st.write(row['question'])

            if isinstance(row['choices'], str) and row['choices'].strip():
                st.markdown("**ë³´ê¸°**")
                for choice in row['choices'].split("|"):
                    st.write("- " + choice.strip())

            with st.expander("âœ… ì •ë‹µ ë³´ê¸° / í•´ì„¤ ë³´ê¸°"):
                st.markdown("**ì •ë‹µ:**")
                st.write(row['answer'])
                st.markdown("**í•´ì„¤:**")
                st.write(row['explanation'])

st.markdown("---")

# --------------------------------------------------
# ëŒ€í™” ê¸°ë¡ ì„¹ì…˜
# --------------------------------------------------
st.markdown("## ğŸ’¬ ëŒ€í™” ê¸°ë¡")

if len(st.session_state["history"]) == 0:
    st.write("ì•„ì§ ëŒ€í™”ê°€ ì—†ì–´ìš” ğŸ™‡")
else:
    for turn in st.session_state["history"]:
        if turn["role"] == "user":
            st.markdown(f"**ğŸ™‹ ì‚¬ìš©ì:** {turn['content']}")
        else:
            st.markdown(f"**ğŸ¤– ì±—ë´‡:** {turn['content']}")

